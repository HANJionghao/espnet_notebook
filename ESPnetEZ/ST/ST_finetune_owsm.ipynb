{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OWSM Fine-tuning for Speech Translation\n",
    "\n",
    "This Jupyter notebook provides a step-by-step guide on using the ESPnetEZ module to fine-tune the OWSM model. In this demonstration, we will leverage the `MuST-C-v2` dataset (English to German subset) to fine-tune an OWSM model for the Speech Translation (ST) task.\n",
    "\n",
    "In this notebook, we assume that you have already downloaded the `MuST-C-v2` dataset and created the dump file using the recipe. If you haven't done this and are unfamiliar with the recipes provided in ESPnet, you can refer to the data preparation sections in the `train_from_scratch.ipynb` or `finetune_owsm.ipynb` notebooks in the ASR demos.\n",
    "\n",
    "Author: Masao Someki [@Masao-Someki](https://github.com/Masao-Someki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install espnet if you haven't it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U espnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import necessary libraries and set several hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from espnet2.layers.create_adapter_fn import create_lora_adapter\n",
    "\n",
    "import espnetez as ez\n",
    "\n",
    "FINETUNE_MODEL = \"espnet/owsm_v3.1_ebf_base\"\n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "DUMP_DIR = \"./dump/raw\"\n",
    "EXP_DIR = \"./exp/train_owsm_base_finetune\"\n",
    "STATS_DIR = \"./exp/stats_owsm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "\n",
    "Let's prepare the `build_model_fn` function for the Trainer. We will use the OWSM-v3.1-ebf-base model, which has approximately 100 million parameters.\n",
    "\n",
    "Please note that we cannot initialize the model outside of a function. When using a multi-GPU environment, we need to initialize the model for each GPU individually. Therefore, it is easier to run the model initialization function for each GPU rather than copying the model. Hence, we need to write the initialization code inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_fn(args):\n",
    "    pretrained_model = Speech2Text.from_pretrained(\n",
    "        FINETUNE_MODEL,\n",
    "        beam_size=10,\n",
    "    )\n",
    "    model = pretrained_model.s2t_model\n",
    "    model.train()\n",
    "    print(f'Trainable parameters: {count_parameters(model)}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bulid_model_fn` function loads a pretrained speech-to-text model, and initializes it for training. It also prints the number of trainable parameters in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Since we assume that you have already generated the dump file using the recipe, we only need to write a simple dictionary for the data preparation.\n",
    "\n",
    "However, please note that currently, ESPnetEZ does not support the combination of lambda functions and lists of data. Therefore, we need to prepare `text_prev` manually, which is simply the `<na>` symbol for all data entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be executed outside of this notebook to prepare <na> for all data\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def rewrite(tp):\n",
    "    with open(tp / \"text\", \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    nas = []\n",
    "    for line in lines:\n",
    "        id_utt, text = line.split(' ', maxsplit=1)\n",
    "        nas.append(f'{id_utt} <na>')\n",
    "\n",
    "    with open(tp / \"text_na\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(nas))\n",
    "\n",
    "\n",
    "rewrite(Path(\"dump/raw/train.en-de_sp\"))\n",
    "rewrite(Path(\"dump/raw/dev.en-de\"))\n",
    "rewrite(Path(\"dump/raw/tst-COMMON.en-de\"))\n",
    "rewrite(Path(\"dump/raw/tst-HE.en-de\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = {\n",
    "    \"speech\": [\"wav.scp\", \"kaldi_ark\"],\n",
    "    \"text\": [\"text.tc.de\", \"text\"],\n",
    "    \"text_prev\": [\"text_na\", \"text\"],\n",
    "    \"text_ctc\": [\"text\", \"text\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Now let's set up the training configuration for the OWSM finetuning. Basically all configurations are the same as the OWSM training, but we will change some parameters for this finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training config from the pretrained model.\n",
    "from espnet2.bin.s2t_inference import Speech2Text\n",
    "pretrained_model = Speech2Text.from_pretrained(\n",
    "    FINETUNE_MODEL,\n",
    "    # category_sym=\"<en>\",\n",
    "    beam_size=10,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "training_config = vars(pretrained_model.s2t_train_args)\n",
    "del pretrained_model\n",
    "\n",
    "# update config for finetuning if needed\n",
    "# For the configuration, please refer to the last cell in this notebook.\n",
    "finetune_config = ez.config.update_finetune_config(\n",
    "    \"s2t\",\n",
    "    training_config,\n",
    "    f\"owsm_finetune_base.yaml\"\n",
    ")\n",
    "\n",
    "# When you don't use yaml file, you can load finetune_config in the following way.\n",
    "# task_class = ez.task.get_ez_task(\"s2t\")\n",
    "# default_config = task_class.get_default_config()\n",
    "# training_config = default_config.update(your_config_in_dict)\n",
    "\n",
    "# Currently ESPnetEZ does not work with the `multiple-iterator` mode.\n",
    "finetune_config['multiple_iterator'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we have everything prepared, we can start training the OWSM model for ST task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ez.Trainer(\n",
    "    task=\"s2t\",\n",
    "    train_config=finetune_config,\n",
    "    train_dump_dir=f\"{DUMP_DIR}/train.en-de_sp\",\n",
    "    valid_dump_dir=f\"{DUMP_DIR}/dev.en-de\",\n",
    "    data_info=data_info,\n",
    "    build_model_fn=build_model_fn,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1,\n",
    ")\n",
    "trainer.collect_stats()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "seed: 2022\n",
    "num_workers: 8\n",
    "batch_type: unsorted\n",
    "batch_size: 1\n",
    "batch_bins: 500000\n",
    "accum_grad: 1\n",
    "max_epoch: 10\n",
    "patience: none\n",
    "init: none\n",
    "best_model_criterion:\n",
    "-   - valid\n",
    "    - acc\n",
    "    - max\n",
    "keep_nbest_models: 3\n",
    "use_amp: true\n",
    "ngpu: 1\n",
    "\n",
    "optim: adamw\n",
    "optim_conf:\n",
    "    lr: 0.0001\n",
    "    weight_decay: 0.000001\n",
    "scheduler: warmuplr\n",
    "scheduler_conf:\n",
    "    warmup_steps: 15000\n",
    "\n",
    "specaug: specaug\n",
    "specaug_conf:\n",
    "    apply_time_warp: true\n",
    "    time_warp_window: 5\n",
    "    time_warp_mode: bicubic\n",
    "    apply_freq_mask: true\n",
    "    freq_mask_width_range:\n",
    "    - 0\n",
    "    - 27\n",
    "    num_freq_mask: 2\n",
    "    apply_time_mask: true\n",
    "    time_mask_width_ratio_range:\n",
    "    - 0.\n",
    "    - 0.05\n",
    "    num_time_mask: 5\n",
    "\n",
    "\n",
    "use_preprocessor: false\n",
    "preprocessor: default\n",
    "preprocessor_conf:\n",
    "    fs: 16000\n",
    "    text_name:\n",
    "        - \"text\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
